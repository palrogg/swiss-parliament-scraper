{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Liste des élus romands"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "members_response = requests.get('http://ws-old.parlament.ch/councillors/basicdetails?format=json', headers={'Accept': 'application/json'})\n",
    "members = members_response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(245, 16)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# liste des elus\n",
    "df = pd.DataFrame(members)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(62, 16)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# romands seulement\n",
    "df = df[df['canton'].isin(['VD', 'GE', 'FR', 'JU', 'VS', 'NE'])].copy()\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Liste des interventions (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.firefox.firefox_binary import FirefoxBinary\n",
    "binary = FirefoxBinary('/Applications/Firefox_32.app/Contents/MacOS/firefox-bin')\n",
    "driver = webdriver.Chrome(r'_helpers/chromedriver')\n",
    "from time import sleep\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## On va prendre les Jurassiens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ju = df[df['canton'] == 'JU']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_id = df_ju['id'].values[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "member_speeches = 'https://www.parlament.ch/fr/ratsbetrieb/suche-Amtliches-bulletin#Default=%7B%22k%22:%22PdSubjectSpeakerPersonNumbers:{member_id}%22%7D'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(member_speeches.format(member_id=test_id))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "rows = []\n",
    "continueScraping = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSpeeches():\n",
    "    search_group = WebDriverWait(driver, 10).until(\n",
    "        EC.presence_of_element_located((By.CSS_SELECTOR, '#Groups .ms-srch-group'))\n",
    "    )\n",
    "    \n",
    "    if not search_group:\n",
    "        return False\n",
    "    \n",
    "    # On parcourt l’innerHTML avec BeautifulSoup\n",
    "    doc = BeautifulSoup(search_group.get_attribute('innerHTML'), 'html.parser')\n",
    "    \n",
    "    results = doc.select('.ms-srch-item')\n",
    "\n",
    "    current_rows = []\n",
    "    for result in results:\n",
    "        link = 'https://www.parlament.ch' + result.find('a').get('href')\n",
    "        label = result.find('h4').text.strip()\n",
    "        no = result.find('div', {'class': 'ms-srch-item-excerpt'}).find('span').string\n",
    "        title = result.find('div', {'class': 'ms-srch-item-excerpt'}).find_all('span')[1].string\n",
    "        current_rows.append([no, label, title, link])\n",
    "    print(len(current_rows), 'rows found.')\n",
    "    return current_rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n",
      "10 rows found.\n"
     ]
    }
   ],
   "source": [
    "while continueScraping:\n",
    "    scraping_result = getSpeeches()\n",
    "    if scraping_result:\n",
    "        rows.extend(scraping_result)\n",
    "        #dfi = pd.DataFrame(rows, columns=['no', 'label', 'title', 'link'])\n",
    "        last_result_year = re.match('.*\\.(\\d{4}).*', scraping_result[-1][1]).group(1)\n",
    "        if int(last_result_year) < 2015:\n",
    "            print('Before 2014, so we stop')\n",
    "            continueScraping = False\n",
    "        \n",
    "        # prochaine page?\n",
    "        nextPageLink = WebDriverWait(driver, 5).until(\n",
    "                EC.presence_of_element_located((By.CSS_SELECTOR, '#PageLinkNext'))\n",
    "            )\n",
    "        if nextPageLink:\n",
    "            nextPageLink.click()\n",
    "            sleep(5)\n",
    "            getSpeeches()\n",
    "    else:\n",
    "        print('Last page, so we stop')\n",
    "        continueScraping = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_member = pd.DataFrame(rows, columns=['no', 'label', 'title', 'href'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(86, 4)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a regarder de plus pres\n",
    "df_member.drop_duplicates(subset=['no']).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_member.to_csv('data/speech_list/{}.csv'.format(test_id))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Scraping des interventions (test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_href = df_member['href'].values[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get(speech_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problème: l’intervention peut être noyée parmi celles des autres, non?\n",
    "# On pourrait récupérer les résumés au stade 2 et voir si ça matche"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plus simple: on merge les duplicates, et on checke avec l’id de l’élu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transcripts = WebDriverWait(driver, 10).until(\n",
    "    EC.presence_of_element_located((By.CSS_SELECTOR, '#areaDebates'))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = BeautifulSoup(transcripts.get_attribute('innerHTML'), 'html.parser')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "speeches = doc.select('.pd-person-description')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# on fera un iterrow() sur le df des élus\n",
    "row = df_ju.iloc[0]\n",
    "memberId = row['biographyUrl'].split('=')[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nom trouvé: Fridez Pierre-Alain\n",
      "match avec le no de l’élu: 4074\n",
      "Nom trouvé: Amherd Viola\n",
      "Pas de lien sur le nom: Amherd Viola\n"
     ]
    }
   ],
   "source": [
    "member_speeches = []\n",
    "for speech in speeches:\n",
    "    member_href = speech.find('a', {'class': 'person-name'})\n",
    "    if member_href:\n",
    "        print('Nom trouvé:', member_href.text.strip())\n",
    "    \n",
    "        if member_href.get('href'):\n",
    "            if member_href.get('href').split('=')[-1] == memberId:\n",
    "                print('match avec le no de l’élu:', memberId)\n",
    "                if len(speech.find_all('p')) > 1:\n",
    "                    print('merde, il peut y avoir > 1 paragraphe => à revoir')\n",
    "                member_speeches.append(speech.find('p').text)\n",
    "            else:\n",
    "                print('Pas de match')\n",
    "        else:\n",
    "            print('Pas de lien sur le nom:', member_href.string.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a merger avec bio des élus\n",
    "df_speeches = pd.DataFrame(member_speeches, columns=['Texte ou intervention'])\n",
    "df_speeches.to_csv('data/{}_{}.csv'.format(test_id, row['lastName']), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
